{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Chatbot\n",
    "* 앱을 새로 깔 필요가 없음\n",
    "* 앱을 깔필요가 없으니 배울 것도 없음\n",
    "* 편한 UX - 그냥 텍스트 치면됨\n",
    "* 즉각적인 Feedback\n",
    "\n",
    "## Seq2Seq를 활용한 간단한 Q/A 봇을 만들어보자\n",
    "![이미지](http://suriyadeepan.github.io/img/seq2seq/seq2seq2.png)\n",
    "* Python 3.5, Tensorflow 1.1, Konlpy (Mecab),Word2Vec (Gensim), matplotlib (Graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import tensorflow as tf\n",
    "from eunjeon import Mecab\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "mecab = Mecab()\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seq2seq를 위한 Data 구성\n",
    "* 질의 응답별로 LIST로 구성\n",
    "* operator사용 value값 기준 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['안녕']\n",
      "['만나', '서', '반가워']\n",
      "['넌', '누구', '니']\n",
      "['나', '는', 'AI', '봇', '이', '란다', '.']\n",
      "['피자', '주문', '할께']\n",
      "['페파', '로니', '주문', '해', '줘']\n",
      "['음료', '는', '멀', '로']\n",
      "['콜라', '로', '해', '줘']\n"
     ]
    }
   ],
   "source": [
    "train_data = [\n",
    "    ['안녕', '만나서 반가워'],\n",
    "    ['넌누구니', '나는 AI 봇이란다.'],\n",
    "    ['피자 주문 할께', '페파로니 주문해줘'],\n",
    "    ['음료는 멀로', '콜라로 해줘']\n",
    "]\n",
    "\n",
    "\n",
    "all_input_sentences = []\n",
    "all_target_sentences = []\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "for row_data in train_data:\n",
    "\n",
    "    print(mecab.morphs(row_data[0]))\n",
    "    print(mecab.morphs(row_data[1]))\n",
    "    input_morphs = mecab.morphs(row_data[0])\n",
    "    output_morphs = mecab.morphs(row_data[1])\n",
    "    tokenizer.fit_on_texts(input_morphs)\n",
    "    tokenizer.fit_on_texts(output_morphs)\n",
    "    all_input_sentences.append(input_morphs)\n",
    "    all_target_sentences.append(output_morphs)\n",
    "\n",
    "input_texts = tokenizer.texts_to_sequences(all_input_sentences)\n",
    "output_texts = tokenizer.texts_to_sequences(all_target_sentences)\n",
    "\n",
    "MAX_NB_WORDS = len(tokenizer.word_index) + 1\n",
    "MAX_SEQUENCE_LENGTH_X = max([len(seq) for seq in input_texts])\n",
    "MAX_SEQUENCE_LENGTH_Y = max([len(seq) for seq in output_texts])\n",
    "MAX_SEQUENCE_LENGTH = max(MAX_SEQUENCE_LENGTH_X, MAX_SEQUENCE_LENGTH_Y)\n",
    "\n",
    "input_texts = pad_sequences(input_texts, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "output_texts = pad_sequences(output_texts, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector 구성 (입력된 문장의 글자별 Vector)\n",
    " - 일반적으로 처리단위가 작아질수록 미등록어에서 자유롭고 작은 vector 차원을 유지할 수 있지만\n",
    " - 문장의 길이가 길어지고, 학습이 어려워지는 문제가 있기에 적절한 embedding을 찾아야하는데 \n",
    " - 이부분은 Biz Domain 별 차이가 있음 복잡도나 표현 가능성등을 적절한 균형에서 찾아야함 \n",
    " - 아래 소스는 이해하기 쉽도록 글자단위의 Onehot으로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: '는', 2: '주문', 3: '해', 4: '줘', 5: '로', 6: '안녕', 7: '만나', 8: '서', 9: '반가워', 10: '넌', 11: '누구', 12: '니', 13: '나', 14: 'ai', 15: '봇', 16: '이', 17: '란다', 18: '피자', 19: '할께', 20: '페파', 21: '로니', 22: '음료', 23: '멀', 24: '콜라'}\n"
     ]
    }
   ],
   "source": [
    "index_word = {v: k for k, v in tokenizer.word_index.items()}\n",
    "print(index_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encodeing\n",
    "* '안녕??'의 정렬하여 1의 값으로 정렬 <br>\n",
    "안 [1, 0, 0, 0, 0, 0, 0, 0, 0, 0] <br>\n",
    "녕 [0, 1, 0, 0, 0, 0, 0, 0, 0, 0] <br>\n",
    "? [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.utils import np_utils\n",
    "input_texts = np_utils.to_categorical(input_texts,25)\n",
    "output_texts = np_utils.to_categorical(output_texts,25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 150)               105600    \n",
      "_________________________________________________________________\n",
      "repeat_vector (RepeatVector) (None, 5, 150)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 5, 150)            180600    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 5, 25)             3775      \n",
      "=================================================================\n",
      "Total params: 289,975\n",
      "Trainable params: 289,975\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.layers import LSTM, RepeatVector, TimeDistributed, Dense, Flatten\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "model = Sequential()\n",
    "model.add(LSTM(150, input_shape=(MAX_SEQUENCE_LENGTH, MAX_NB_WORDS)))\n",
    "model.add(RepeatVector(MAX_SEQUENCE_LENGTH))\n",
    "model.add(LSTM(150, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(MAX_NB_WORDS, activation='softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input text :안녕\n",
      "output text :줘줘줘줘줘\n",
      "input text :넌누구니\n",
      "output text :만나만나만나만나만나\n",
      "input text :피자 주문 할께\n",
      "output text :넌넌넌넌넌\n",
      "input text :음료는 멀로\n",
      "output text :란다란다란다란다란다\n"
     ]
    }
   ],
   "source": [
    "def inference_embed(data) :\n",
    "    mecab = Mecab()\n",
    "    encode_raw = mecab.morphs(data)\n",
    "    output = tokenizer.texts_to_sequences([encode_raw])\n",
    "    output = pad_sequences(output, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    output = np_utils.to_categorical(output, MAX_NB_WORDS)\n",
    "    return output\n",
    "\n",
    "def predict(data):\n",
    "    x_predict = inference_embed(data)\n",
    "    y = model.predict(x_predict, verbose=0)\n",
    "    arr = []\n",
    "    for dim in y[0]:\n",
    "        arr.append(dim.argmax())\n",
    "    index_word = {v: k for k, v in tokenizer.word_index.items()}  # map back\n",
    "    words = []\n",
    "    for seq in arr:\n",
    "        if(seq == 0):\n",
    "            words.append('')\n",
    "        else:\n",
    "            words.append(index_word.get(seq))\n",
    "    output_text = ''.join(words)\n",
    "    print('input text :' + data)\n",
    "    print('output text :' + output_text)  # output\n",
    "\n",
    "predict('안녕')\n",
    "predict('넌누구니')\n",
    "predict('피자 주문 할께')\n",
    "predict('음료는 멀로')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
